{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3478f3b7",
   "metadata": {},
   "source": [
    "### Data preprocessing for Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "712e3240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e668720",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06a5cee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"spam.csv\",encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dbe8ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['v1', 'v2', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a01b9d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...        NaN   \n",
       "6   ham  Even my brother is not like to speak with me. ...        NaN   \n",
       "7   ham  As per your request 'Melle Melle (Oru Minnamin...        NaN   \n",
       "8  spam  WINNER!! As a valued network customer you have...        NaN   \n",
       "9  spam  Had your mobile 11 months or more? U R entitle...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  \n",
       "5        NaN        NaN  \n",
       "6        NaN        NaN  \n",
       "7        NaN        NaN  \n",
       "8        NaN        NaN  \n",
       "9        NaN        NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e720fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v1               0\n",
       "v2               0\n",
       "Unnamed: 2    5522\n",
       "Unnamed: 3    5560\n",
       "Unnamed: 4    5566\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d324f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63079780",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "953ca583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "df.v2= df.v2.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8b544f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go until jurong point, crazy.. available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar... joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say so early hor... u c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2\n",
       "0   ham  go until jurong point, crazy.. available only ...\n",
       "1   ham                      ok lar... joking wif u oni...\n",
       "2  spam  free entry in 2 a wkly comp to win fa cup fina...\n",
       "3   ham  u dun say so early hor... u c already then say...\n",
       "4   ham  nah i don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "093aa849",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-5323897f5ace>:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.v2= df.v2.str.replace(\"[^A-Za-z]\",\" \")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry in a wkly comp to win fa cup final ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah i don t think he goes to usf he lives arou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>freemsg hey there darling it s been week s now...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>even my brother is not like to speak with me t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>as per your request melle melle oru minnaminun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>winner as a valued network customer you have b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>had your mobile months or more u r entitled to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2\n",
       "0   ham  go until jurong point crazy available only in ...\n",
       "1   ham                           ok lar joking wif u oni \n",
       "2  spam  free entry in a wkly comp to win fa cup final ...\n",
       "3   ham       u dun say so early hor u c already then say \n",
       "4   ham  nah i don t think he goes to usf he lives arou...\n",
       "5  spam  freemsg hey there darling it s been week s now...\n",
       "6   ham  even my brother is not like to speak with me t...\n",
       "7   ham  as per your request melle melle oru minnaminun...\n",
       "8  spam  winner as a valued network customer you have b...\n",
       "9  spam  had your mobile months or more u r entitled to..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace special character\n",
    "df.v2= df.v2.str.replace(\"[^A-Za-z]\",\" \")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7f7e08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-aeb4f18b2fb4>:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.v2= df.v2.str.replace(\"\\s+\",\" \")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry in a wkly comp to win fa cup final ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah i don t think he goes to usf he lives arou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>freemsg hey there darling it s been week s now...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>even my brother is not like to speak with me t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>as per your request melle melle oru minnaminun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>winner as a valued network customer you have b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>had your mobile months or more u r entitled to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2\n",
       "0   ham  go until jurong point crazy available only in ...\n",
       "1   ham                           ok lar joking wif u oni \n",
       "2  spam  free entry in a wkly comp to win fa cup final ...\n",
       "3   ham       u dun say so early hor u c already then say \n",
       "4   ham  nah i don t think he goes to usf he lives arou...\n",
       "5  spam  freemsg hey there darling it s been week s now...\n",
       "6   ham  even my brother is not like to speak with me t...\n",
       "7   ham  as per your request melle melle oru minnaminun...\n",
       "8  spam  winner as a valued network customer you have b...\n",
       "9  spam  had your mobile months or more u r entitled to..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace 's'\n",
    "df.v2= df.v2.str.replace(\"\\s+\",\" \")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbdb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe942c7",
   "metadata": {},
   "source": [
    "# Bag of Words using CountVectorizer\n",
    "- Count Vectorizer is a way to convert a given set of strings into a frequency representation\n",
    "- inability in identifying more important and less important words for analysis\n",
    "- consider words that are abundant in a corpus as the most statistically significant word\n",
    "- doesn't identify the relationships between words such as linguistic similarity between words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f65bf1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97aa566b",
   "metadata": {},
   "source": [
    "**1. Simple unigram tokens: break into words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6a94ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate model\n",
    "cv= CountVectorizer(ngram_range=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf1710fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5572x7682 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 71870 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the vectorizer\n",
    "cv_transform= cv.fit_transform(df.v2) # return an array\n",
    "cv_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20b0f084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_transform= cv_transform.toarray()\n",
    "cv_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30cd3197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 7682)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_transform.shape #row x columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1285c281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7682"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cv.get_feature_names()) # columns name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e31d8094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aah</th>\n",
       "      <th>aaniye</th>\n",
       "      <th>aaooooright</th>\n",
       "      <th>aathi</th>\n",
       "      <th>ab</th>\n",
       "      <th>abbey</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>abeg</th>\n",
       "      <th>abel</th>\n",
       "      <th>...</th>\n",
       "      <th>zeros</th>\n",
       "      <th>zf</th>\n",
       "      <th>zhong</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zs</th>\n",
       "      <th>zyada</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7682 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa  aah  aaniye  aaooooright  aathi  ab  abbey  abdomen  abeg  abel  ...  \\\n",
       "0   0    0       0            0      0   0      0        0     0     0  ...   \n",
       "1   0    0       0            0      0   0      0        0     0     0  ...   \n",
       "2   0    0       0            0      0   0      0        0     0     0  ...   \n",
       "3   0    0       0            0      0   0      0        0     0     0  ...   \n",
       "4   0    0       0            0      0   0      0        0     0     0  ...   \n",
       "\n",
       "   zeros  zf  zhong  zindgi  zoe  zogtorius  zoom  zouk  zs  zyada  \n",
       "0      0   0      0       0    0          0     0     0   0      0  \n",
       "1      0   0      0       0    0          0     0     0   0      0  \n",
       "2      0   0      0       0    0          0     0     0   0      0  \n",
       "3      0   0      0       0    0          0     0     0   0      0  \n",
       "4      0   0      0       0    0          0     0     0   0      0  \n",
       "\n",
       "[5 rows x 7682 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to dataframe\n",
    "df_CountVectorizer= pd.DataFrame(cv_transform,columns=cv.get_feature_names())\n",
    "df_CountVectorizer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3795fbbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>aa</th>\n",
       "      <th>aah</th>\n",
       "      <th>aaniye</th>\n",
       "      <th>aaooooright</th>\n",
       "      <th>aathi</th>\n",
       "      <th>ab</th>\n",
       "      <th>abbey</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>abeg</th>\n",
       "      <th>...</th>\n",
       "      <th>zeros</th>\n",
       "      <th>zf</th>\n",
       "      <th>zhong</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zs</th>\n",
       "      <th>zyada</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7683 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1  aa  aah  aaniye  aaooooright  aathi  ab  abbey  abdomen  abeg  ...  \\\n",
       "0   ham   0    0       0            0      0   0      0        0     0  ...   \n",
       "1   ham   0    0       0            0      0   0      0        0     0  ...   \n",
       "2  spam   0    0       0            0      0   0      0        0     0  ...   \n",
       "3   ham   0    0       0            0      0   0      0        0     0  ...   \n",
       "4   ham   0    0       0            0      0   0      0        0     0  ...   \n",
       "\n",
       "   zeros  zf  zhong  zindgi  zoe  zogtorius  zoom  zouk  zs  zyada  \n",
       "0      0   0      0       0    0          0     0     0   0      0  \n",
       "1      0   0      0       0    0          0     0     0   0      0  \n",
       "2      0   0      0       0    0          0     0     0   0      0  \n",
       "3      0   0      0       0    0          0     0     0   0      0  \n",
       "4      0   0      0       0    0          0     0     0   0      0  \n",
       "\n",
       "[5 rows x 7683 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_CountVectorizer =pd.concat([df.v1,df_CountVectorizer],axis=1)\n",
    "df_CountVectorizer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95911447",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "291411b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary= df_CountVectorizer.iloc[:,1:].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e847e265",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.columns=['word','count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2aeb7a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7637</th>\n",
       "      <td>you</td>\n",
       "      <td>2243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6798</th>\n",
       "      <td>to</td>\n",
       "      <td>2242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6666</th>\n",
       "      <td>the</td>\n",
       "      <td>1332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>and</td>\n",
       "      <td>979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3185</th>\n",
       "      <td>in</td>\n",
       "      <td>902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word  count\n",
       "7637  you   2243\n",
       "6798   to   2242\n",
       "6666  the   1332\n",
       "241   and    979\n",
       "3185   in    902"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary.sort_values('count',ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f383ae2f",
   "metadata": {},
   "source": [
    "**2. Using stopwords: remove stopwords**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e8dc0bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate model\n",
    "cv_stopwords= CountVectorizer(ngram_range=(1, 1),stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e5c2944",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_stopwords_transform= cv_stopwords.fit_transform(df.v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "92a40ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_stopwords_transform= cv_stopwords_transform.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e974d116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 7414)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_stopwords_transform.shape # a reduce of around 200 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b9b108f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "about,above,across,after,afterwards,again,against,all,almost,alone,along,already,also,although,always,am,among,amongst,amount,an,and,another,any,anyhow,anyone,anything,anyway,anywhere,are,around,as,at,back,be,because,become,becomes,been,before,beforehand,behind,being,beside,between,beyond,bill,both,bottom,but,by,call,can,cannot,cant,co,could,cry,de,describe,detail,do,done,down,due,during,each,eg,eight,either,eleven,else,elsewhere,empty,enough,etc,even,ever,every,everyone,everything,everywhere,except,few,fifteen,fifty,fill,find,fire,first,five,for,found,four,from,front,full,further,get,give,go,had,has,hasnt,have,he,hence,her,here,herself,him,himself,his,how,however,hundred,ie,if,in,inc,indeed,interest,into,is,it,its,itself,keep,last,least,less,ltd,made,many,may,me,meanwhile,might,mine,more,most,mostly,move,much,must,my,myself,name,neither,never,next,no,nobody,none,nor,not,nothing,now,nowhere,of,off,often,on,once,one,only,onto,or,other,others,otherwise,our,ours,out,over,own,part,per,perhaps,please,put,rather,re,same,see,seem,seemed,seems,serious,several,she,should,show,side,since,six,so,some,someone,something,sometime,sometimes,somewhere,still,such,system,take,ten,than,that,the,their,them,then,there,these,they,thin,this,those,though,three,through,thru,thus,to,together,too,top,towards,twelve,twenty,two,un,under,until,up,upon,us,very,via,was,we,well,were,what,whatever,when,whenever,where,wherever,whether,which,while,who,whole,whom,whose,why,will,with,within,without,would,yet,you,your,yours,yourself,"
     ]
    }
   ],
   "source": [
    "# check what stopword have been reduce\n",
    "for a in cv.get_feature_names(): \n",
    "    if a not in cv_stopwords.get_feature_names():\n",
    "        print(a,end=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dbe3ee74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to dataframe\n",
    "cv_stopwords_transform= pd.DataFrame(cv_stopwords_transform,columns=cv_stopwords.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ddd941e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6846</th>\n",
       "      <td>ur</td>\n",
       "      <td>385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3315</th>\n",
       "      <td>just</td>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2668</th>\n",
       "      <td>gt</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3716</th>\n",
       "      <td>lt</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4404</th>\n",
       "      <td>ok</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2377</th>\n",
       "      <td>free</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3622</th>\n",
       "      <td>ll</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3409</th>\n",
       "      <td>know</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3569</th>\n",
       "      <td>like</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2582</th>\n",
       "      <td>good</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>day</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600</th>\n",
       "      <td>got</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>come</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6539</th>\n",
       "      <td>time</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3694</th>\n",
       "      <td>love</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5588</th>\n",
       "      <td>send</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6431</th>\n",
       "      <td>text</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7026</th>\n",
       "      <td>want</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6739</th>\n",
       "      <td>txt</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2569</th>\n",
       "      <td>going</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index    0\n",
       "6846     ur  385\n",
       "3315   just  371\n",
       "2668     gt  318\n",
       "3716     lt  316\n",
       "4404     ok  292\n",
       "2377   free  288\n",
       "3622     ll  269\n",
       "3409   know  261\n",
       "3569   like  245\n",
       "2582   good  245\n",
       "1516    day  242\n",
       "2600    got  240\n",
       "1215   come  230\n",
       "6539   time  220\n",
       "3694   love  209\n",
       "5588   send  199\n",
       "6431   text  195\n",
       "7026   want  195\n",
       "6739    txt  184\n",
       "2569  going  173"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_stopwords_transform.sum().reset_index().sort_values(0,ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13c0376",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "341620e2",
   "metadata": {},
   "source": [
    "**3.Only consider certain pattern + using stopwords** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "af6e8b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider words with at least 3 letter\n",
    "cv_stopwords_3letter= CountVectorizer(ngram_range=(1, 1),stop_words='english',token_pattern=r'\\b[a-zA-Z]{4,}\\b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a971b6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_stopwords_3letter_transform= cv_stopwords_3letter.fit_transform(df.v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "be8cf061",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_stopwords_3letter_transform= cv_stopwords_3letter_transform.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "87ddcce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 6448)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_stopwords_3letter_transform.shape # reducing around 1000 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cf469f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aa,aah,ab,abi,abj,abt,ac,acc,acl,aco,act,ad,add,adi,adp,ads,ae,aft,ag,age,ago,ah,aha,aid,aig,ain,air,aj,ak,aka,al,ali,ami,amk,amp,ams,amt,amy,ana,ans,aom,apo,app,apr,apt,aq,ar,ard,arm,arr,art,asa,ask,asp,ass,ate,atm,av,ava,ave,avo,aww,ax,ay,ayn,ayo,ba,bac,bad,bag,bak,bam,bao,bar,bat,bay,bb,bbc,bbd,bbq,bc,bck,bcm,bcz,bec,bed,beg,ben,bet,bf,bid,big,bin,bit,biz,bk,blu,bmw,bob,boo,bot,box,boy,bp,bpo,brb,bro,bsn,bt,btw,bud,bus,buy,bw,bx,bye,cab,cal,cam,car,cat,cbe,cc,cd,cds,cer,ch,cha,chg,chk,cl,cld,cm,cme,cn,cnl,cnn,com,cos,coz,cps,cr,cro,cs,csc,csh,cst,cts,cud,cum,cup,cut,cuz,cw,cya,da,dad,dai,dan,dao,das,dat,day,db,dd,dec,def,del,dem,den,der,dey,dha,di,did,die,din,dip,dis,dl,dlf,dnt,dob,doc,dog,dom,don,dot,dps,dr,dry,dsn,dt,dub,dun,duo,dvd,dvg,dwn,dx,ea,ear,eat,ec,ed,edu,ee,eek,egg,ego,eh,el,ela,em,emc,en,enc,end,eng,epi,er,ere,erm,err,ese,eta,eva,eve,evn,evo,evr,ew,ex,exe,exp,ext,ey,eye,ez,fa,fab,fal,fan,far,fat,fav,fb,feb,fed,ff,fil,fit,fix,fl,fly,fm,fml,fne,fo,fox,fps,fr,fri,frm,fro,ft,ful,fun,fwd,fyi,ga,gal,gam,gap,gas,gay,gb,gbp,gd,ge,gee,gei,gek,gep,ger,gf,gin,giv,glo,gm,gmw,gn,god,gon,got,gpu,gr,gre,grl,grr,gt,gua,gud,gut,guy,gv,gym,ha,haf,hai,ham,hat,hav,hb,hcl,hdd,hee,hen,hep,hes,hex,hey,hf,hg,hi,hip,hit,hl,hlp,hm,hme,hmm,hmv,ho,hol,hon,hoo,hop,hor,hos,hot,hp,hr,hrs,hu,hug,huh,hui,hum,hun,hut,hv,hw,iam,ias,ibh,ibm,ibn,ic,ice,id,idc,idk,idu,iff,ig,il,ill,im,imf,img,imp,ing,ink,inr,ip,iq,ish,isn,itz,ive,iyo,iz,ja,jam,jan,jap,jas,jay,jaz,jb,jd,je,jen,jet,jez,jhl,ji,jia,jiu,jjc,jo,job,jod,jog,jon,jos,jot,joy,jp,js,jst,jul,jus,juz,jx,jy,kay,kb,ke,ken,key,kfc,kg,ki,kid,kip,kit,kl,knw,ko,kr,ktv,kvb,kz,la,lab,lac,lag,lap,lar,law,lay,lb,ld,ldn,le,leg,leh,lei,leo,les,let,lf,li,lib,lie,lik,lil,lim,lip,lit,lk,ll,llc,lo,log,lol,loo,lor,lot,lou,lov,low,lp,ls,lst,lt,lul,luv,lux,lv,lyf,lyk,ma,mac,mad,mag,mah,man,map,mas,mat,max,mb,mc,mca,mcr,med,mee,meg,meh,mei,mel,men,met,mf,mfl,mgs,mi,mia,mid,min,mis,mix,mj,mk,ml,mls,mm,mmm,mns,mo,mob,mom,mon,mp,mph,mr,mre,mro,mrt,mrw,ms,msg,msn,mt,mth,mu,mum,mus,muz,mw,mys,na,nag,nah,nan,nap,nat,nav,nb,nd,ne,ned,neo,net,new,nhs,ni,nic,nig,nit,noe,noi,nok,non,nos,nr,nri,nt,nte,ntt,num,nus,nvm,nvq,nw,nxt,ny,nyc,nyt,nz,odi,oga,oh,oi,oic,oil,oja,ok,ola,old,oli,omg,omw,oni,ooh,opt,orc,ore,org,orh,ors,oru,os,oso,ou,ovr,ow,owe,owl,owo,oz,pa,pai,pan,pap,pax,pay,pc,pee,pei,pen,pes,pg,ph,phb,phd,php,pic,pie,pig,pin,pix,pl,plm,pls,plz,pm,pmt,po,pod,poo,pop,pos,pp,ppl,ppm,ppt,pre,pro,ps,psp,pt,pub,pw,px,qet,qf,qi,qp,qu,que,qxj,raj,ran,rcb,rcd,rct,rcv,rd,rdy,rec,red,ree,ref,reg,rem,rg,rip,rob,ron,ros,row,rp,rpl,rr,rs,rt,rtf,rtm,rto,ru,rub,rum,run,rv,rvx,rw,rwm,sac,sad,sae,sam,sao,sar,sat,saw,say,sc,sch,sd,se,sea,sec,sed,sef,seh,sem,sen,set,sex,sez,sf,sg,sh,sha,shb,shd,shu,shy,si,sib,sic,sim,sip,sir,sis,sit,sk,sky,slo,slp,sms,sn,snd,soc,sol,soo,sos,soz,sp,spk,spl,sq,sri,srs,srt,sry,ss,st,std,sth,str,sts,stu,sub,sue,sum,sun,sup,sux,svc,sw,swt,syd,ta,tag,tai,taj,tap,tat,tau,tb,tbs,tc,tcr,tcs,te,tea,tee,tel,tex,tf,tg,th,thk,thm,tho,ths,tht,thx,thy,tie,til,tim,tip,tis,tix,tiz,tke,tlk,tlp,tm,tmr,tms,tmw,tnc,toa,tog,tok,tol,tom,tor,tot,tp,tr,try,ts,tt,tue,tui,tul,tv,txt,ubi,ud,ugh,ugo,uh,uin,uk,ukp,uks,um,uni,upd,ups,ur,ure,url,urn,usa,usb,usc,use,usf,uup,uv,uve,uz,va,vat,vco,ve,vic,vid,vip,vl,vry,vs,vth,vu,wa,wad,wah,wan,wap,wat,way,waz,wb,wc,web,wed,wee,wen,wer,wet,whn,whr,wi,wid,wif,wil,win,wit,wiv,wk,wkg,wks,wld,wml,wn,wnt,wo,won,woo,wot,wow,wp,wq,wr,wrc,wrd,wrk,ws,wt,wtc,wtf,wth,wu,wud,wun,wv,www,wx,xam,xe,xh,xin,xn,xt,xx,xxx,xy,ya,yah,yam,yan,yar,yay,yck,yeh,yen,yep,yer,yes,yf,yhl,yi,ym,yo,yor,yr,yrs,yt,yun,yuo,yup,zac,zed,zf,zoe,zs,"
     ]
    }
   ],
   "source": [
    "# check what words have been deleted\n",
    "for a in cv_stopwords.get_feature_names(): \n",
    "    if a not in cv_stopwords_3letter.get_feature_names():\n",
    "        print(a,end=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "583725bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conver to dataframe\n",
    "cv_stopwords_3letter_transform= pd.DataFrame(cv_stopwords_3letter_transform,columns=cv_stopwords_3letter.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "52e70e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2901</th>\n",
       "      <td>just</td>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2115</th>\n",
       "      <td>free</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2980</th>\n",
       "      <td>know</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3111</th>\n",
       "      <td>like</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2288</th>\n",
       "      <td>good</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>come</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5732</th>\n",
       "      <td>time</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3221</th>\n",
       "      <td>love</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4867</th>\n",
       "      <td>send</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6148</th>\n",
       "      <td>want</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5637</th>\n",
       "      <td>text</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2276</th>\n",
       "      <td>going</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3657</th>\n",
       "      <td>need</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554</th>\n",
       "      <td>home</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5351</th>\n",
       "      <td>stop</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5760</th>\n",
       "      <td>today</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5174</th>\n",
       "      <td>sorry</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4591</th>\n",
       "      <td>reply</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>dont</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3496</th>\n",
       "      <td>mobile</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index    0\n",
       "2901    just  371\n",
       "2115    free  288\n",
       "2980    know  261\n",
       "3111    like  245\n",
       "2288    good  245\n",
       "1077    come  230\n",
       "5732    time  220\n",
       "3221    love  209\n",
       "4867    send  199\n",
       "6148    want  195\n",
       "5637    text  195\n",
       "2276   going  173\n",
       "3657    need  168\n",
       "2554    home  167\n",
       "5351    stop  163\n",
       "5760   today  160\n",
       "5174   sorry  160\n",
       "4591   reply  148\n",
       "1579    dont  144\n",
       "3496  mobile  144"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_stopwords_3letter_transform.sum().reset_index().sort_values(0,ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06f18ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f6e2320",
   "metadata": {},
   "source": [
    "**4.Consider only bigrams tokens: 2 words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "439a6e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_bigrams= CountVectorizer(ngram_range=(2, 2),stop_words='english',token_pattern=r'\\b[a-zA-Z]{4,}\\b',min_df=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bf6c78c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_bigrams_transform=cv_bigrams.fit_transform(df.v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9c347080",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_bigrams_transform= cv_bigrams_transform.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "24b8db8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 3324)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_bigrams_transform.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1a29e2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_bigrams_transform=pd.DataFrame(cv_bigrams_transform,columns=cv_bigrams.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1627fe0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2613</th>\n",
       "      <td>sorry later</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>good morning</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>send stop</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2193</th>\n",
       "      <td>prize guaranteed</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1898</th>\n",
       "      <td>national rate</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2445</th>\n",
       "      <td>selected receive</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>good night</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>await collection</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>customer service</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069</th>\n",
       "      <td>urgent mobile</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>land line</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>happy year</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2187</th>\n",
       "      <td>prize claim</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>free entry</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>identifier code</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>account statement</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2465</th>\n",
       "      <td>send message</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>come home</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>dont know</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2184</th>\n",
       "      <td>private account</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  index   0\n",
       "2613        sorry later  39\n",
       "1042       good morning  32\n",
       "2475          send stop  22\n",
       "2193   prize guaranteed  22\n",
       "1898      national rate  20\n",
       "2445   selected receive  19\n",
       "1046         good night  19\n",
       "115    await collection  19\n",
       "549    customer service  19\n",
       "3069      urgent mobile  18\n",
       "1437          land line  18\n",
       "1139         happy year  18\n",
       "2187        prize claim  17\n",
       "883          free entry  16\n",
       "1257    identifier code  16\n",
       "18    account statement  16\n",
       "2465       send message  16\n",
       "425           come home  16\n",
       "661           dont know  16\n",
       "2184    private account  16"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_bigrams_transform.sum().reset_index().sort_values(0, ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3596b50d",
   "metadata": {},
   "source": [
    "# TF-IDF\n",
    "- not only focuses on the frequency of words present in the corpus but also provides the importance of the words\n",
    "- The term \"tf\" is basically the count of a word in a sentence\n",
    "- the term \"df\" is called document frequency which means in how many documents the word \"subfield\" is present within corpus\n",
    "- TFIDF is based on the logic that words that are too abundant in a corpus and words that are too rare are both not statistically important for finding a pattern.\n",
    "- Higher value of tfidf signifies higher importance of the words in the corpus while lower values represent lower importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cbaf4d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c88a3f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf= TfidfVectorizer(stop_words='english',token_pattern=r'\\b[a-zA-Z]{4,}\\b')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cbc0cc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_transform= tf_idf.fit_transform(df.v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5026b953",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_transform= tf_idf_transform.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "389bb750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 6448)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_transform.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "82d91e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_transform= pd.DataFrame(tf_idf_transform,columns=tf_idf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8ec213a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2901</th>\n",
       "      <td>just</td>\n",
       "      <td>84.185419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>come</td>\n",
       "      <td>79.292683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2980</th>\n",
       "      <td>know</td>\n",
       "      <td>67.897897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2288</th>\n",
       "      <td>good</td>\n",
       "      <td>67.392938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5732</th>\n",
       "      <td>time</td>\n",
       "      <td>66.623380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554</th>\n",
       "      <td>home</td>\n",
       "      <td>66.128679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3111</th>\n",
       "      <td>like</td>\n",
       "      <td>65.380595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3037</th>\n",
       "      <td>later</td>\n",
       "      <td>65.344062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5174</th>\n",
       "      <td>sorry</td>\n",
       "      <td>65.033585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2115</th>\n",
       "      <td>free</td>\n",
       "      <td>62.666897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2276</th>\n",
       "      <td>going</td>\n",
       "      <td>60.048546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4867</th>\n",
       "      <td>send</td>\n",
       "      <td>55.951157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6148</th>\n",
       "      <td>want</td>\n",
       "      <td>54.901076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3221</th>\n",
       "      <td>love</td>\n",
       "      <td>49.685546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5637</th>\n",
       "      <td>text</td>\n",
       "      <td>48.983618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3657</th>\n",
       "      <td>need</td>\n",
       "      <td>48.915730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5760</th>\n",
       "      <td>today</td>\n",
       "      <td>45.280548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>dont</td>\n",
       "      <td>43.713560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5603</th>\n",
       "      <td>tell</td>\n",
       "      <td>42.743719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5685</th>\n",
       "      <td>think</td>\n",
       "      <td>41.700590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index          0\n",
       "2901   just  84.185419\n",
       "1077   come  79.292683\n",
       "2980   know  67.897897\n",
       "2288   good  67.392938\n",
       "5732   time  66.623380\n",
       "2554   home  66.128679\n",
       "3111   like  65.380595\n",
       "3037  later  65.344062\n",
       "5174  sorry  65.033585\n",
       "2115   free  62.666897\n",
       "2276  going  60.048546\n",
       "4867   send  55.951157\n",
       "6148   want  54.901076\n",
       "3221   love  49.685546\n",
       "5637   text  48.983618\n",
       "3657   need  48.915730\n",
       "5760  today  45.280548\n",
       "1579   dont  43.713560\n",
       "5603   tell  42.743719\n",
       "5685  think  41.700590"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_transform.sum().reset_index().sort_values(0,ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e2c138",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
